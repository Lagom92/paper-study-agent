{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Conventional RAG based on LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 논문의 내용을 전부 프롬프트에 넣어서 질문하면 대답을 잘할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Paper-Agent\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(project_name=\"Paper-Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지수: 19\n"
     ]
    }
   ],
   "source": [
    "loader = PyMuPDFLoader(\n",
    "    \"../data/Retrieval Augmented Generation for Knowledge Intensive NLP Tasks.pdf\"\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"문서의 페이지수: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69059\n",
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n",
      "†Facebook AI Research; ‡University \n"
     ]
    }
   ],
   "source": [
    "paper_contents = \"\"\n",
    "\n",
    "for i in range(len(docs)):\n",
    "    paper_contents += docs[i].page_content\n",
    "\n",
    "print(len(paper_contents))\n",
    "print(paper_contents[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": lambda x: paper_contents, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: RunnableLambda(lambda x: paper_contents),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nAnswer in Korean.\\n\\n#Context: \\n{context}\\n\\n#Question:\\n{question}\\n\\n#Answer:\")\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10c411b90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10e4ed910>, root_client=<openai.OpenAI object at 0x10a7a78d0>, root_async_client=<openai.AsyncOpenAI object at 0x10c48cf90>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "논문의 제목은 \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"입니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행(Run Chain)\n",
    "question = \"이 논문의 제목 알려줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 논문은 지식 집약적인 자연어 처리(NLP) 작업을 위한 검색 증강 생성(Retrieval-Augmented Generation, RAG) 모델에 대해 다루고 있습니다. RAG 모델은 사전 학습된 시퀀스-투-시퀀스(seq2seq) 모델과 위키피디아의 밀집 벡터 인덱스를 결합하여, 검색 기반의 비매개변수 메모리를 활용하여 언어 생성을 수행합니다. 이 논문은 RAG 모델이 다양한 지식 집약적인 NLP 작업에서 최첨단 성능을 달성하며, 특히 개방형 도메인 질문 응답 작업에서 뛰어난 성과를 보인다고 설명합니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행(Run Chain)\n",
    "question = \"이 논문의 주제가 무엇이야?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 논문의 저자는 Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela입니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행(Run Chain)\n",
    "question = \"이 논문의 저자가 누구야?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 논문의 초록에서는 대규모 사전 학습된 언어 모델이 매개변수에 사실적 지식을 저장할 수 있으며, 하위 NLP 작업에 맞게 미세 조정되었을 때 최첨단 결과를 달성할 수 있음을 보여줍니다. 그러나 이러한 모델의 지식 접근 및 조작 능력은 여전히 제한적이며, 지식 집약적인 작업에서는 작업별 아키텍처에 비해 성능이 뒤처집니다. 또한, 모델의 결정에 대한 출처를 제공하고 세계 지식을 업데이트하는 것은 여전히 연구 과제로 남아 있습니다. 이 논문에서는 사전 학습된 매개변수 및 비매개변수 메모리를 결합하여 언어 생성을 수행하는 RAG(Retrieval-Augmented Generation) 모델을 소개합니다. 이 모델은 사전 학습된 seq2seq 모델을 매개변수 메모리로, Wikipedia의 밀집 벡터 인덱스를 비매개변수 메모리로 사용합니다. 다양한 지식 집약적인 NLP 작업에서 모델을 미세 조정하고 평가하여 세 가지 공개 도메인 QA 작업에서 최첨단 성능을 달성했으며, 매개변수 seq2seq 모델과 작업별 검색 및 추출 아키텍처를 능가했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행(Run Chain)\n",
    "question = \"이 논문의 Abstract 설명해줘.\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "- 논문 전체 내용을 넣어버리면 원하는 결과가 나오기는 함\n",
    "- 하지만 시간도 더 오래 걸리고 토큰 사용량도 많아짐(RAG 사용시 약 1,400 --> 전체 텍스트 사용시 약 18,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
